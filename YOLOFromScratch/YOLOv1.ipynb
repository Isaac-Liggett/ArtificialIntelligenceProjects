{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cadc326",
   "metadata": {},
   "source": [
    "# YOLOv1 From Scratch\n",
    "\n",
    "This is a demonstration of my learning with object detection and pytorch. I will use similar principles as used in the YOLO models to train a one shot detector network using the COCO 2017 dataset. The object detector will be trained to identify the first ten classes in the dataset:\n",
    "<table style=\"background-color:white\">\n",
    "    <tr>\n",
    "        <td style=\"width:25%; font-size:15px;\">\n",
    "            <ul style=\"text-align:left;width:150%\">\n",
    "                <li>Person</li>\n",
    "                <li>Bicycle</li>\n",
    "                <li>Car</li>\n",
    "                <li>Motorcycle</li>\n",
    "                <li>Airplane</li>\n",
    "                <li>Bus</li>\n",
    "                <li>Train</li>\n",
    "                <li>Truck</li>\n",
    "                <li>Boat</li>  \n",
    "                <li>Traffic Light</li>\n",
    "            </ul>\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"yolov1.jpg\" width=\"75%\"/>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e59315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFile\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "from time import sleep\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import random\n",
    "import sys\n",
    "import matplotlib.ticker as plticker\n",
    "from datetime import datetime\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "from torchvision.ops import box_iou \n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import IterableDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439e39c5",
   "metadata": {},
   "source": [
    "# Creating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1a11a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class COCODatasetOD(Dataset):\n",
    "    def __init__(self, filepath, device=\"cpu\", image_size=416, cells=10, Shuffle=False, testdataset=False):\n",
    "        if testdataset:\n",
    "            self.apath = os.path.join(filepath, \"annotations\", \"instances_val2017.json\")\n",
    "            self.ipath = os.path.join(filepath, \"val2017\")\n",
    "        else:\n",
    "            self.apath = os.path.join(filepath, \"annotations\", \"instances_train2017.json\")\n",
    "            self.ipath = os.path.join(filepath, \"train2017\")\n",
    "        \n",
    "        self.image_size = (image_size, image_size)\n",
    "        self.cells = cells\n",
    "        self.cell_size = 1 / self.cells\n",
    "        self.classes = 10\n",
    "        self.device = device\n",
    "        \n",
    "        with open(self.apath, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            newdata = dict()\n",
    "\n",
    "            for image in data['images']:\n",
    "                image_id = image['id']\n",
    "                if image_id not in newdata:\n",
    "                    newdata[image_id] = image\n",
    "            for annotation in data['annotations']:\n",
    "                image_id = annotation['image_id']\n",
    "                classification = annotation['category_id']\n",
    "\n",
    "                if image_id in newdata:\n",
    "                    if 'annotations' in newdata[image_id] and classification <= self.classes: # only get the first 10 classes\n",
    "                        newdata[image_id]['annotations'].append(annotation)\n",
    "                    elif classification <= 10 and 'annotations' not in newdata[image_id]:\n",
    "                        newdata[image_id]['annotations'] = [annotation]\n",
    "            self.annotations = list(dict({key: newdata[key] for key in newdata if 'annotations' in newdata[key]}).values())\n",
    "            if Shuffle:\n",
    "                random.shuffle(self.annotations)\n",
    "                \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        annotation = self.annotations[index]\n",
    "        image_width, image_height = annotation['width'], annotation['height']\n",
    "        \n",
    "        #Load the image\n",
    "        image = Image.open(os.path.join(self.ipath, annotation['file_name'])).convert('RGB').resize(self.image_size)\n",
    "        \n",
    "        #Prepare the annotations\n",
    "        processed_annotations = np.zeros((self.cells, self.cells, self.classes+5))\n",
    "        \n",
    "        for a in annotation['annotations']:\n",
    "            bbox = a['bbox'] # (x, y, w, h)\n",
    "            rbbox = [bbox[0]/image_width, bbox[1]/image_height, bbox[2]/image_width, bbox[3]/image_height] #relative position\n",
    "            \n",
    "            mx, my = (rbbox[0]+(rbbox[0]+rbbox[2]))/2, (rbbox[1]+(rbbox[1]+rbbox[3]))/2\n",
    "            rcellX, rcellY = mx/self.cell_size, my/self.cell_size\n",
    "            rcellw, rcellh = rbbox[2]/self.cell_size, rbbox[3]/self.cell_size\n",
    "            \n",
    "            posX, posY = int(np.floor(rcellX)), int(np.floor(rcellY))\n",
    "            offsetX, offsetY = rcellX % 1, rcellY % 1\n",
    "            \n",
    "            ohe_classes = np.zeros(self.classes)\n",
    "            ohe_classes[a['category_id'] - 1] = 1\n",
    "            \n",
    "            # [x_position, y_position, width, height, confidence... one hot encoded classes confidence]\n",
    "            insert = np.concatenate(([offsetX, offsetY, rcellw, rcellh, 1], ohe_classes))\n",
    "            processed_annotations[posX][posY] = insert\n",
    "            \n",
    "            flattened_annotations = processed_annotations.reshape(processed_annotations.shape[0]*processed_annotations.shape[1]*processed_annotations.shape[2])\n",
    "            \n",
    "            totensor = T.ToTensor()\n",
    "            \n",
    "        return totensor(image).to(self.device), torch.tensor(flattened_annotations.astype(float), dtype=torch.float).to(self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4e1ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayImageWithLabels(img, label):\n",
    "    fig, ax = plt.subplots(1)\n",
    "\n",
    "    image = np.transpose(img, (1, 2, 0))\n",
    "    ax.imshow(image)\n",
    "    \n",
    "    for x in range(len(label)):\n",
    "        for y in range(len(label[x])):\n",
    "            if label[x][y][0] != 0:\n",
    "                cell_size_x, cell_size_y = len(image) / len(label), len(image[0]) / len(label[0])\n",
    "                mx, my = ((x)*cell_size_x)+(cell_size_x*label[x][y][0]), ((y)*cell_size_y)+(cell_size_y*label[x][y][1])\n",
    "                w, h = (cell_size_x*label[x][y][2]), (cell_size_y*label[x][y][3])\n",
    "\n",
    "                circle = patches.Circle((mx,my), 2, color=\"orange\")\n",
    "                rect = patches.Rectangle(((mx-(w/2)),(my-(h/2))), w, h, edgecolor='r', facecolor=\"None\")\n",
    "                ax.add_patch(circle)            \n",
    "                ax.add_patch(rect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e738b01",
   "metadata": {},
   "source": [
    "# Making a custom loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53965482",
   "metadata": {},
   "source": [
    "The yolo loss function is defined as with the YOLOv1 paper on https://arxiv.org/abs/1506.02640. I had to do alot of other research to work out what exactly was happening with the loss function as there is alot of relatively complex math that could be hard to understand at a High-School level.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0647316",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOLoss(nn.Module):\n",
    "    def __init__(self, cells, classes):\n",
    "        super(YOLOLoss, self).__init__()\n",
    "        self.cells = cells\n",
    "        self.classes = classes\n",
    "        \n",
    "    def forward(self, output, target): \n",
    "        cel = nn.CrossEntropyLoss()\n",
    "        totalLoss = 0\n",
    "        \n",
    "        for batch in range(len(output)):\n",
    "            for index in range(self.cells**2):\n",
    "                if torch.is_nonzero(output[batch][index*15]):\n",
    "                    #coordinate loss\n",
    "                    coordinate_loss = ((output[batch][index*15:(index*15)+1] - target[batch][index*15:(index*15)+1])**2) + (((torch.sqrt(output[batch][(index*15)+2]) - torch.sqrt(target[batch][(index*15)+2]))**2)+((torch.sqrt(output[batch][(index*15)+3]) - torch.sqrt(target[batch][(index*15)+3]))**2))\n",
    "                    \n",
    "                    #confidence loss\n",
    "                    confidence_loss = -(target[batch][(index*15)+4] * torch.log(output[batch][(index*15)+4] + 1e-9) + (1 - target[batch][(index*15)+4]) * torch.log(1 - output[batch][(index*15)+4] + 1e-9))\n",
    "\n",
    "                    #class loss\n",
    "                    class_loss = torch.sum(torch.sub( target[batch][(index*15)+5:(index*15)+14], output[batch][(index*15)+5:(index*15)+14] )**2)\n",
    "                    #print(coordinate_loss, confidence_loss, class_loss)\n",
    "                    totalLoss += (coordinate_loss + confidence_loss + class_loss)\n",
    "        return totalLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d424fd0c",
   "metadata": {},
   "source": [
    "# Custom Activation Function\n",
    "The network output requires that a custom activation function be made so that the class losses represent probabilities through the softmax activation function and positional (x, y) information and confidence scores be normalized between 0 and 1 using the sigmoid activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4d0db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOActivation(nn.Module):\n",
    "    def __init__(self, classes, cells=7):\n",
    "        super(YOLOActivation, self).__init__()\n",
    "        self.classes = classes\n",
    "        self.cells = cells\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, input_):\n",
    "        for batch in range(len(input_)):\n",
    "            for i in range((self.cells**2)-1):\n",
    "                input_[batch][(i*(self.classes+5))+5:(i*(self.classes+5))+5+self.classes] = self.softmax(input_[batch][(i*(self.classes+5))+5:(i*(self.classes+5))+5+self.classes])\n",
    "                input_[batch][(i*(self.classes+5)):(i*(self.classes+5))+2] = self.sigmoid(input_[batch][(i*(self.classes+5)):(i*(self.classes+5))+2])\n",
    "                input_[batch][(i*(self.classes+5))+4] = self.sigmoid(input_[batch][(i*(self.classes+5))+4])\n",
    "        return input_     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ddf78f",
   "metadata": {},
   "source": [
    "# Initializing the Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e749b1e5",
   "metadata": {},
   "source": [
    "The Network was initialized as per the paper. Note how i also added a dropout layer between the convolutional and dense layers as this would provide an added challenge for the network and prevent overfitting whilst presenting it with noisey data so it can perform better under different circumstances. The 50% probability of the dropout layer was just arbitrary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a0ff8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOv1(nn.Module):\n",
    "    def __init__(self, cells=7, classes=10):\n",
    "        super(YOLOv1, self).__init__()\n",
    "        self.normalisation = nn.BatchNorm2d(3)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.conv1 = nn.Conv2d(3, 64, 7, stride=2)\n",
    "        self.max1 = nn.MaxPool2d(2, stride=2)\n",
    "            \n",
    "        self.conv2 = nn.Conv2d(64, 192, 3)\n",
    "        self.max2 = nn.MaxPool2d(2, stride=2)\n",
    "            \n",
    "        self.conv3 = nn.Conv2d(192, 128, 1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 3)\n",
    "        self.conv5 = nn.Conv2d(256, 256, 1)\n",
    "        self.conv6 = nn.Conv2d(256, 512, 3)\n",
    "        self.max3 = nn.MaxPool2d(2, stride=2)\n",
    "            \n",
    "        self.conv7 = nn.Conv2d(512, 256, 1)\n",
    "        self.conv8 = nn.Conv2d(256, 512, 3)\n",
    "        self.conv9 = nn.Conv2d(512, 256, 1)\n",
    "        self.conv10 = nn.Conv2d(256, 512, 3)\n",
    "        self.conv11 = nn.Conv2d(512, 512, 1)\n",
    "        self.conv12 = nn.Conv2d(512, 1024, 3)\n",
    "        self.max4 = nn.MaxPool2d(2, stride=2)\n",
    "            \n",
    "        self.conv13 = nn.Conv2d(1024, 512, 1)\n",
    "        self.conv14 = nn.Conv2d(512, 1024, 3)\n",
    "        self.conv15 = nn.Conv2d(1024, 512, 1)\n",
    "        self.conv16 = nn.Conv2d(512, 1024, 3)\n",
    "        self.conv17 = nn.Conv2d(1024, 1024, 3)\n",
    "        self.conv18 = nn.Conv2d(1024, 1024, 3, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "            \n",
    "        self.linear1 = nn.Linear(1024, 4096)\n",
    "        self.linear2 = nn.Linear(4096, 7*7*(classes+5))\n",
    "        self.yoloactivation = YOLOActivation(cells=cells, classes=classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.normalisation(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.max1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.max2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.max3(x)\n",
    "        \n",
    "        x = self.conv7(x)\n",
    "        x = self.conv8(x)\n",
    "        x = self.conv9(x)\n",
    "        x = self.conv10(x)\n",
    "        x = self.conv11(x)\n",
    "        x = self.conv12(x)\n",
    "        x = self.max4(x)\n",
    "        \n",
    "        x = self.conv13(x)\n",
    "        x = self.conv14(x)\n",
    "        x = self.conv15(x)\n",
    "        x = self.conv16(x)\n",
    "        x = self.conv17(x)\n",
    "        x = self.conv18(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.yoloactivation(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbafb61f",
   "metadata": {},
   "source": [
    "# The Training Loop\n",
    "This is where the network would be trained for 50 epochs and the results could be evaluated to determine the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c6c126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    train_ds = COCODatasetOD(\"./coco2017\", Shuffle=False, cells=7, image_size=448, device=device)\n",
    "    test_ds = COCODatasetOD(\"./coco2017\", Shuffle=False, cells=7, image_size=448, testdataset=True, device=device)\n",
    "\n",
    "    train_dataloader = DataLoader(dataset=train_ds, batch_size=5, shuffle=True, num_workers=4)\n",
    "    test_dataloader = DataLoader(dataset=test_ds, batch_size=5, shuffle=True, num_workers=4)\n",
    "    \n",
    "    # define the model\n",
    "    model = YOLOv1().to(device)\n",
    "\n",
    "    # define the loss function and optimizer\n",
    "    loss_fn = YOLOLoss(cells=7, classes=10)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "    scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "    # defining Tensorboard writer\n",
    "    writer = SummaryWriter('data/runs')\n",
    "\n",
    "    # training specific parameters\n",
    "    num_epochs = 50\n",
    "\n",
    "    # training function\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0\n",
    "        running_accuracy = 0\n",
    "        starttime = datetime.now()\n",
    "\n",
    "        print(f\"COMMENCING EPOCH {epoch+1}\")\n",
    "        training_data = tqdm(train_dataloader, leave=True)\n",
    "\n",
    "        for batch_idx, (images, annotations) in enumerate(training_data):\n",
    "            model.train(True)\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = loss_fn(outputs, annotations)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            running_accuracy += torch.mean(torch.sub(annotations, outputs)).item()\n",
    "\n",
    "            for param in model.parameters():\n",
    "                param.grad = None\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.train(False)\n",
    "        model.eval()\n",
    "\n",
    "        testing_loss = 0\n",
    "        testing_accuracy = 0\n",
    "        # evaluate testing data\n",
    "        for i, (img, ann) in enumerate(test_dataloader):\n",
    "            if i < 10:\n",
    "                test_output = model(img)\n",
    "                test_loss = loss_fn(test_output, ann)\n",
    "                testing_accuracy += torch.mean(torch.sub(ann, test_outputs)).item()\n",
    "            else:\n",
    "                testing_loss = testing_loss / 10\n",
    "                testing_accuracy = testing_accuracy / 10\n",
    "                break\n",
    "\n",
    "        print (f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {running_loss/len(training_data)}, Average Accuracy: {running_accuracy/len(training_data)}')\n",
    "        writer.add_scalar('training loss', running_loss/len(training_data), epoch+1)\n",
    "        writer.add_scalar('training accuracy', running_accuracy/len(training_data), epoch+1)\n",
    "        writer.add_scalar('testing loss', testing_loss, epoch+1)\n",
    "        writer.add_scalar('testing accuracy', testing_accuracy, epoch+1)\n",
    "\n",
    "        scheduler.step()\n",
    "        torch.save(model.state_dict(f\"data/saves/{starttime}_{datetime.now()}_EPOCH{epoch+1}\"))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c798fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchvenv",
   "language": "python",
   "name": "pytorchvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
